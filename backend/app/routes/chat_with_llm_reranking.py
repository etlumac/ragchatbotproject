from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from openai import OpenAI
import os
import json
import traceback
from dotenv import load_dotenv
from pathlib import Path
import re
from slugify import slugify
from typing import List

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ .env
load_dotenv()

# –ß–∏—Ç–∞–µ–º API-–∫–ª—é—á –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise ValueError("‚ùå –û—à–∏–±–∫–∞: API-–∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω! –£–∫–∞–∂–∏—Ç–µ –µ–≥–æ –≤ .env –∏–ª–∏ –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è.")

# –ü—É—Ç–∏
VECTOR_DB_PATH = Path("static/vectorstore")
METADATA_PATH = Path("static/metadata.json")  # –§–∞–π–ª —Å –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö
READER_MODEL_NAME = "deepseek/deepseek-chat"

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º OpenAI –∫–ª–∏–µ–Ω—Ç
client = OpenAI(
    api_key=OPENAI_API_KEY,
    base_url="https://api.vsegpt.ru/v1",
)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º FastAPI —Ä–æ—É—Ç–µ—Ä
router = APIRouter()

# ‚úÖ –û–ø–∏—Å–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∑–∞–ø—Ä–æ—Å–∞
class ChatRequest(BaseModel):
    query: str
    document_name: str  # –î–æ–±–∞–≤–ª—è–µ–º –∏–º—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞

def safe_filename(filename: str) -> str:
    """–ü—Ä–∏–≤–æ–¥–∏—Ç –∏–º—è —Ñ–∞–π–ª–∞ –∫ –µ–¥–∏–Ω–æ–º—É –±–µ–∑–æ–ø–∞—Å–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É."""
    name, ext = os.path.splitext(filename)
    safe_name = slugify(name, allow_unicode=False)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º ASCII-only slugify
    return f"{safe_name}{ext}"

def load_metadata():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö."""
    if METADATA_PATH.exists():
        with open(METADATA_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}

def find_vector_store(document_name: str) -> Path:
    """–ò—â–µ—Ç FAISS-—Ö—Ä–∞–Ω–∏–ª–∏—â–µ, —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è—è `metadata.json`, –∑–∞—Ç–µ–º —á–µ—Ä–µ–∑ `safe_filename`."""

    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –≤ –±–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
    document_name_safe = safe_filename(document_name)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    metadata = load_metadata()

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—É—Ç—å –≤ metadata.json
    if document_name_safe in metadata and "vector_index" in metadata[document_name_safe]:
        vector_index_path = Path(metadata[document_name_safe]["vector_index"])
        if vector_index_path.exists() and vector_index_path.is_dir():
            return vector_index_path

    # –ï—Å–ª–∏ –ø—É—Ç–∏ –Ω–µ—Ç –≤ metadata.json, –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø—É—Ç—å
    vector_index_path = VECTOR_DB_PATH / f"{document_name_safe}.faiss"
    if vector_index_path.exists() and vector_index_path.is_dir():
        return vector_index_path

    raise HTTPException(status_code=500, detail=f"‚ùå –í–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ `{document_name_safe}` –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç —Å–Ω–æ–≤–∞.")


def rerank_documents_with_llm_and_vector(
    question: str,
    vector_scored_docs: List[tuple],  # (Document, vector_score)
    client: OpenAI,
    vector_weight: float = 0.3,
    llm_weight: float = 0.7
) -> List[tuple]:
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç LLM-—Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å —É—á—ë—Ç–æ–º –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Å–∫–æ—Ä–∞.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫: (–¥–æ–∫—É–º–µ–Ω—Ç, —Ñ–∏–Ω–∞–ª—å–Ω—ã–π_—Å–∫–æ—Ä)
    """
    reranked_docs = []

    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è vector_score (FAISS similarity) –¥–æ [0, 1]
    scores = [score for _, score in vector_scored_docs]
    max_score, min_score = max(scores), min(scores)
    score_range = max_score - min_score if max_score != min_score else 1.0

    for doc, vector_score in vector_scored_docs:
        try:
            norm_vector_score = (vector_score - min_score) / score_range

            prompt = generate_rerank_prompt(doc.page_content, question)

            messages = [
                {"role": "system", "content": "–í—ã –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∞—è –º–æ–¥–µ–ª—å, –æ—Ü–µ–Ω–∏–≤–∞—é—â–∞—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å."},
                {"role": "user", "content": prompt}
            ]

            completion = client.chat.completions.create(
                model=READER_MODEL_NAME,
                messages=messages,
                temperature=0.1,
                max_tokens=50,
            )

            llm_score = float(re.findall(r"0(?:\.\d+)?|1(?:\.0+)?", completion.choices[0].message.content)[0])
            final_score = (norm_vector_score * vector_weight) + (llm_score * llm_weight)

            reranked_docs.append((doc.page_content, final_score))
            print(f"üìä norm_vector: {norm_vector_score:.2f}, llm: {llm_score:.2f}, final: {final_score:.3f}")

        except Exception as e:
            print("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–µ:", traceback.format_exc())
            reranked_docs.append((doc.page_content, 0.0))  # fallback

    return sorted(reranked_docs, key=lambda x: x[1], reverse=True)

def generate_rerank_prompt(document_text: str, question: str) -> str:
    return f"""
    –í–∞–º –Ω—É–∂–Ω–æ –æ—Ü–µ–Ω–∏—Ç—å, –Ω–∞—Å–∫–æ–ª—å–∫–æ –¥–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –ø–æ–ª–µ–∑–µ–Ω –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å. –û—Ç–≤–µ—Ç—å—Ç–µ –Ω–∞ –≤–æ–ø—Ä–æ—Å, —É–∫–∞–∑–∞–≤ —Å—Ç–µ–ø–µ–Ω—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —à–∫–∞–ª–µ –æ—Ç 0 –¥–æ 1, –≥–¥–µ:

    0 = –ê–±—Å–æ–ª—é—Ç–Ω–æ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π: —Ç–µ–∫—Å—Ç –Ω–µ –∏–º–µ–µ—Ç –æ—Ç–Ω–æ—à–µ–Ω–∏—è –∫ –∑–∞–ø—Ä–æ—Å—É.
    0.1 = –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π: —Ç–æ–ª—å–∫–æ —Å–ª–∞–±–∞—è –∏–ª–∏ –∫–æ—Å–≤–µ–Ω–Ω–∞—è —Å–≤—è–∑—å —Å –∑–∞–ø—Ä–æ—Å–æ–º.
    0.2 = –û—á–µ–Ω—å —Å–ª–∞–±–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π: —Ç–µ–∫—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é —Å–≤—è–∑—å —Å –∑–∞–ø—Ä–æ—Å–æ–º.
    0.3 = –°–ª–∞–±–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π: —Å–≤—è–∑—å —Å–ª–∞–±–∞—è, –Ω–æ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –∞—Å–ø–µ–∫—Ç.
    0.4 = –£–º–µ—Ä–µ–Ω–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π: —Ç–µ–∫—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –∞—Å–ø–µ–∫—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –ø–æ–ª–µ–∑–Ω—ã –¥–ª—è –æ—Ç–≤–µ—Ç–∞.
    0.5 = –°—Ä–µ–¥–Ω–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π: —Ç–µ–∫—Å—Ç –ø–æ–º–æ–≥–∞–µ—Ç, –Ω–æ —Ç—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.
    0.6 = –î–æ–≤–æ–ª—å–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π: —Ç–µ–∫—Å—Ç –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –ø–æ–ª–µ–∑–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –æ—Ç–≤–µ—Ç–∞.
    0.7 = –û—á–µ–Ω—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π: —Ç–µ–∫—Å—Ç –Ω–µ–ø–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ –ø–æ–º–æ–≥–∞–µ—Ç –≤ –æ—Ç–≤–µ—Ç–µ –Ω–∞ –∑–∞–ø—Ä–æ—Å.
    0.8 = –ü–æ—á—Ç–∏ –ø–æ–ª–Ω–æ—Å—Ç—å—é —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π: —Ç–µ–∫—Å—Ç –∏–º–µ–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ –æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫ –∑–∞–ø—Ä–æ—Å—É.
    0.9 = –ü–æ—á—Ç–∏ –∏–¥–µ–∞–ª—å–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π: —Ç–µ–∫—Å—Ç –∏–¥–µ–∞–ª—å–Ω–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–∞.
    1.0 = –ê–±—Å–æ–ª—é—Ç–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π: —Ç–µ–∫—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Å—é –Ω–µ–æ–±—Ö–æ–¥–∏–º—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞.

    –¢–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞:
    "{document_text}"

    –í–æ–ø—Ä–æ—Å:
    "{question}"

    –û—Ü–µ–Ω–∏—Ç–µ —Å—Ç–µ–ø–µ–Ω—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –æ—Ç 0 –¥–æ 1.
    """


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –∑–∞–ø—Ä–æ—Å–æ–≤
def generate_multi_queries(question: str) -> List[str]:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –∑–∞–ø—Ä–æ—Å–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–æ–¥–µ–ª–∏ GPT."""
    try:
        # –°–æ–∑–¥–∞—ë–º –∑–∞–ø—Ä–æ—Å –¥–ª—è –º–æ–¥–µ–ª–∏, —á—Ç–æ–±—ã –æ–Ω–∞ –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞–ª–∞ –≤–æ–ø—Ä–æ—Å
        prompt = (
            f"–ü–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å –æ–¥–Ω–∏–º —Å–ø–æ—Å–æ–±–æ–º  (–Ω–µ –±–æ–ª—å—à–µ!!), —Å–æ—Ö—Ä–∞–Ω—è—è –µ–≥–æ —Å–º—ã—Å–ª: '{question}'. "
            "–ü–æ—Å—Ç–∞—Ä–∞–π—Å—è —Å–¥–µ–ª–∞—Ç—å —ç—Ç–æ —Ç–∞–∫, —á—Ç–æ–±—ã –∫–∞–∂–¥—ã–π –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤–æ–ø—Ä–æ—Å –±—ã–ª —É–Ω–∏–∫–∞–ª—å–Ω—ã–º, –Ω–æ –≤—Å—ë –µ—â—ë —Å–æ—Ö—Ä–∞–Ω—è–ª –∏—Å—Ö–æ–¥–Ω—É—é –∏–¥–µ—é."
        )

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –≤ –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
        messages = [
            {
                "role": "system",
                "content": "–¢—ã –ø–æ–º–æ–≥–∞–µ—à—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º —Å–æ–∑–¥–∞–≤–∞—Ç—å —Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –≤–æ–ø—Ä–æ—Å–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–¥–∞–Ω–Ω–æ–≥–æ. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä—É–π –≤–æ–ø—Ä–æ—Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ —Å–ø–æ—Å–æ–±–∞–º–∏."
            },
            {
                "role": "user",
                "content": prompt
            }
        ]

        print("ü§ñ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞–Ω–∏—è –≤–æ–ø—Ä–æ—Å–∞...")
        completion = client.chat.completions.create(
            model=READER_MODEL_NAME,
            messages=messages,
            temperature=0.7,
            max_tokens=150,
        )

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∏–∑ –æ—Ç–≤–µ—Ç–∞
        generated_queries = completion.choices[0].message.content.strip().split("\n")
        print(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã: {generated_queries}")
        
        return generated_queries

    except Exception as e:
        print("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤:", traceback.format_exc())
        return [question]  # –ï—Å–ª–∏ –æ—à–∏–±–∫–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π –≤–æ–ø—Ä–æ—Å









def answer_with_rag_multi_query(question: str, knowledge_index: FAISS, client: OpenAI):
    print(f"üîç –ó–∞–ø—Ä–æ—Å—ã: {question}")
    
    multi_queries = generate_multi_queries(question)
    combined_scored_docs = []

    try:
        for query in multi_queries:
            relevant_docs = knowledge_index.similarity_search_with_score(query=query, k=5)
            combined_scored_docs.extend(relevant_docs)

        if not combined_scored_docs:
            return "–û—Ç–≤–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö.", []

        # –†–µ—Ä–∞–Ω–∫–∏–Ω–≥ —Å LLM –∏ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π
        reranked_docs = rerank_documents_with_llm_and_vector(
            question=question,
            vector_scored_docs=combined_scored_docs,
            client=client
        )

        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (—Ç–æ–ø-N –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤)
        top_contexts = [doc for doc, _ in reranked_docs[:5]]
        context = "\n".join(top_contexts)

        messages = [
    {
        "role": "system",
        "content": (
            "–í—ã ‚Äî –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∞—è –º–æ–¥–µ–ª—å, –æ—Ç–≤–µ—á–∞—é—â–∞—è –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞. "
            "–í–∞—à –æ—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —á—ë—Ç–∫–∏–º, —Ç–æ—á–Ω—ã–º –∏ —Å—Ç—Ä–æ–≥–æ –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–º –Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞. "
            "–ü–µ—Ä–µ–¥ —Ç–µ–º –∫–∞–∫ –¥–∞—Ç—å –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç, –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ (Chain of Thought), —á—Ç–æ–±—ã –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω–æ –ø—Ä–∏–π—Ç–∏ –∫ –≤—ã–≤–æ–¥—É.\n\n"

            "–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:\n"
            "---\n"
            "**–û—Ç–≤–µ—Ç:**\n"
            "[–ö—Ä–∞—Ç–∫–∏–π –∏ —Ç–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ‚Äî –ø—Ä—è–º–æ —É–∫–∞–∂–∏—Ç–µ —ç—Ç–æ.]\n\n"
            "**–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ:**\n"
            "[–ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —à–∞–≥–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è: —á—Ç–æ –∏—Å–∫–∞–ª–∏, –≥–¥–µ –Ω–∞—à–ª–∏, –ø–æ—á–µ–º—É —ç—Ç–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ. –£–¥–µ–ª–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Å –∑–∞–ø—Ä–æ—Å–æ–º. "
            "–ò–∑–±–µ–≥–∞–π—Ç–µ –ø–æ–¥–º–µ–Ω—ã –ø–æ—Ö–æ–∂–∏—Ö –º–µ—Ç—Ä–∏–∫ –∏–ª–∏ —Ñ–∞–∫—Ç–æ–≤. –ù–µ –¥–µ–ª–∞–π—Ç–µ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏–π.]\n\n"
            "**–í—ã–≤–æ–¥:**\n"
            "[(–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±–æ–±—â–µ–Ω–∏–µ, –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –ø–æ—è—Å–Ω–∏—Ç—å —Å—É—Ç—å –∏–ª–∏ —É—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ –æ—Ç–≤–µ—Ç–µ.]\n"
            "---\n\n"

            "–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è:\n"
            "1. –û–ø—Ä–µ–¥–µ–ª–∏—Ç–µ, –∫–∞–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è –æ—Ç–≤–µ—Ç–∞.\n"
            "2. –ù–∞–π–¥–∏—Ç–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ.\n"
            "3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –ª–∏ –æ–Ω–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –≤–æ–ø—Ä–æ—Å—É, –∞ –Ω–µ –ø—Ä–æ—Å—Ç–æ –ø–æ—Ö–æ–∂–∏.\n"
            "4. –ù–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–π—Ç–µ —Ç–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç –∏–ª–∏ —Å–æ–æ–±—â–∏—Ç–µ, —á—Ç–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ.\n\n"
            "5. –ù–µ —Å—Å—ã–ª–∞–π—Ç–µ—Å—å –Ω–∞ –Ω–∞–∑–≤–∞–Ω–∏—è –∏–ª–∏ –Ω–æ–º–µ—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.–ù–µ —É–∫–∞–∑—ã–≤–∞–π—Ç–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –≤ –ª—é–±–æ–º –≤–∏–¥–µ.\n"


            "–ë—É–¥—å—Ç–µ –æ—Å–æ–±–µ–Ω–Ω–æ –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω—ã –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ —á–∞—Å—Ç–∏—á–Ω—ã—Ö –∏–ª–∏ —Å—Ö–æ–∂–∏—Ö –ø–æ —Å–º—ã—Å–ª—É –¥–∞–Ω–Ω—ã—Ö. –ù–µ –ø–æ–¥–º–µ–Ω—è–π—Ç–µ –∏—Ö —Ü–µ–ª–µ–≤—ã–º–∏. –ù–µ —É–∫–∞–∑—ã–≤–∞–π –≤ –æ—Ç–≤–µ—Ç–µ –∏—Å—Ç–æ—á–Ω–∏–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏."
        )
    },
    {
        "role": "user",
        "content": f"Context:\n{context}\n---\nQuestion: {question}"
    }
]

        completion = client.chat.completions.create(
            model=READER_MODEL_NAME,
            messages=messages,
            temperature=0.1,
        )

        answer = completion.choices[0].message.content
        print(f"‚úÖ –û—Ç–≤–µ—Ç GPT: {answer}")
        return answer, top_contexts

    except Exception as e:
        print("‚ùå –û—à–∏–±–∫–∞:", traceback.format_exc())
        return "–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞.", []













@router.post("/chat/")
async def chat_with_rag(request: ChatRequest):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —á–∞—Ç–∞ —Å MultiQuery: –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –∑–∞–ø—Ä–æ—Å, –∏—â–µ—Ç –≤ FAISS –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º –∑–∞–ø—Ä–æ—Å–∞–º –∏ –æ—Ç–≤–µ—á–∞–µ—Ç —á–µ—Ä–µ–∑ LLM."""
    query = request.query
    document_name = request.document_name
    print(f"üì© –ü–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å: {query} (–î–æ–∫—É–º–µ–Ω—Ç: {document_name})")

    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º FAISS-—Ö—Ä–∞–Ω–∏–ª–∏—â–µ
        vectorstore_folder = find_vector_store(document_name)

        embeddings = OpenAIEmbeddings(
            model="emb-openai/text-embedding-3-small",
            openai_api_key=OPENAI_API_KEY,
            openai_api_base="https://api.vsegpt.ru/v1",
        )

        print(f"üì• –ó–∞–≥—Ä—É–∂–∞–µ–º FAISS –∏–∑ `{vectorstore_folder}`...")
        vector_db = FAISS.load_local(str(vectorstore_folder), embeddings, allow_dangerous_deserialization=True)

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å MultiQuery
        answer, sources = answer_with_rag_multi_query(query, vector_db, client)


        print(f"‚úÖ –û—Ç–≤–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω: {answer}")
        return {"response": answer, "sources": sources}

    except HTTPException as http_ex:
        raise http_ex
    except Exception as e:
        print("‚ùå –û—à–∏–±–∫–∞ –≤ `chat_with_rag_multi_query`:", traceback.format_exc())
        raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞.")